{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  cat_id  seller_id  brand_id  time_stamp  action_type\n",
      "0   328862   323294     833       2882    2661.0         829            0\n",
      "1   328862   844400    1271       2882    2661.0         829            0\n",
      "2   328862   575153    1271       2882    2661.0         829            0\n",
      "3   328862   996875    1271       2882    2661.0         829            0\n",
      "4   328862  1086186    1271       1253    1049.0         829            0\n"
     ]
    }
   ],
   "source": [
    "# Load and check the dataC:\\Users\\matte\\Tsinghua\\BigD\\Project\\data_format1\\data_format1\\test_format1.csv\n",
    "\n",
    "user_logs = pd.read_csv('data_format1/data_format1/user_log_format1.csv')\n",
    "\n",
    "print(user_logs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIuser_logs encoding\n",
    "Itfiuser_logs encodes the cat brand seller item of all user log, retains the topN according to the frequency of occurrence, and avoids too high a dimension\n",
    "Itfiuser_logs encoding is performed on all cat brand items that are interacted with in the store, and the topN items are retained based on the frequency of occurrence to avoid excessive dimensionality.\n",
    "Itfiuser_logs encoding is performed on the cat brand items that match users and stores in the sample, and the topN items are retained based on the frequency of occurrence to avoid excessive dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation\n",
    "user_logs['user_id'] = user_logs['user_id'].astype(np.int32)\n",
    "user_logs['item_id'] = user_logs['item_id'].astype(np.int32)\n",
    "user_logs['cat_id'] = user_logs['cat_id'].astype(np.int16)\n",
    "user_logs['seller_id'] = user_logs['seller_id'].astype(np.int16)\n",
    "user_logs.rename(columns={'seller_id' : 'merchant_id'}, inplace=True)\n",
    "user_logs['brand_id'].fillna(0, inplace=True)\n",
    "user_logs['brand_id'] = user_logs['brand_id'].astype(np.int16)\n",
    "user_logs['time_stamp'] = (pd.to_datetime(user_logs['time_stamp'], format='%m%d') - pd.to_datetime(user_logs['time_stamp'].min(), format='%m%d')).dt.days\n",
    "user_logs['time_stamp'] = user_logs['time_stamp'].astype(np.int16)\n",
    "user_logs['action_type'] = user_logs['action_type'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8444\n",
      "1658\n",
      "1090390\n",
      "424170\n",
      "4995\n"
     ]
    }
   ],
   "source": [
    "print(len(user_logs['brand_id'].unique()))\n",
    "print(len(user_logs['cat_id'].unique()))\n",
    "print(len(user_logs['item_id'].unique()))\n",
    "print(len(user_logs['user_id'].unique()))\n",
    "print(len(user_logs['merchant_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  cat_id     tfidf\n",
      "0   328862     833  0.031020\n",
      "1   328862    1271  0.098857\n",
      "2   328862    1467  0.030949\n",
      "3   328862    1095  0.029926\n",
      "4   328862     602  0.040811\n",
      "        user_id                                        top_5_tfidf\n",
      "0             1  [0.8335644548432335, 0.4706547355921492, 0.254...\n",
      "1             2  [0.37582408192796374, 0.2515851185852035, 0.18...\n",
      "2             3  [0.6968686505976962, 0.37253301987480675, 0.22...\n",
      "3             4  [0.3793766233040169, 0.26735187470922145, 0.16...\n",
      "4             5  [0.27725803294739876, 0.20750181766894002, 0.2...\n",
      "...         ...                                                ...\n",
      "424165   424166  [0.6535020467491037, 0.38608635898093446, 0.24...\n",
      "424166   424167  [0.6398008541301398, 0.35542274500125837, 0.24...\n",
      "424167   424168  [0.42830890690239937, 0.3201519809124793, 0.12...\n",
      "424168   424169  [0.38216923438358263, 0.20247118114713147, 0.1...\n",
      "424169   424170  [0.5933784144461842, 0.431412990270693, 0.2301...\n",
      "\n",
      "[424170 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "user_cat_df = user_logs.copy()\n",
    "user_cat_df.drop(columns=['action_type', 'time_stamp','merchant_id', 'item_id', 'brand_id'], inplace=True)\n",
    "# Step 1: Count occurrences of cat_id for each user_id (Numerator of TF)\n",
    "user_cat_df['cat_count'] = user_cat_df.groupby(['user_id', 'cat_id'])['cat_id'].transform('count')\n",
    "# Step 2: Calculate total interactions for each user_id (Denominator of TF)\n",
    "user_cat_df['total_interactions'] = user_cat_df.groupby('user_id')['cat_id'].transform('count')\n",
    "# Step 3: Calculate TF (Term Frequency)\n",
    "user_cat_df['tf'] = user_cat_df['cat_count'] / user_cat_df['total_interactions']\n",
    "user_cat_df = user_cat_df.drop_duplicates(subset=['user_id', 'cat_id'])\n",
    "\n",
    "# Step 4: Calculate the document frequency (df) for each category (cat_id)\n",
    "df_cat_df = user_cat_df.groupby('cat_id')['user_id'].nunique().reset_index(name='df')\n",
    "\n",
    "# Step 5: Calculate IDF (Inverse Document Frequency)\n",
    "N = user_cat_df['user_id'].nunique()  # Total number of unique users\n",
    "df_cat_df['idf'] = df_cat_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "# Step 6: Merge IDF back into the original DataFrame\n",
    "user_cat_df = user_cat_df.merge(df_cat_df[['cat_id', 'idf']], on='cat_id', how='left')\n",
    "\n",
    "# Step 7: Calculate TF-IDF\n",
    "user_cat_df['tfidf'] = user_cat_df['tf'] * user_cat_df['idf']\n",
    "\n",
    "user_cat_df.drop(columns=['cat_count', 'total_interactions', 'tf','idf'], inplace=True)\n",
    "print(user_cat_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per user_id\n",
    "# Group by user_id and keep the top n TF-IDF values for each user\n",
    "n= 5\n",
    "grouped = (\n",
    "    user_cat_df.groupby('user_id')['tfidf']\n",
    "    .apply(lambda x: sorted(x, reverse=True)[:n])  # Sort and select top n\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'cat_user.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf > 1\n",
      "Empty DataFrame\n",
      "Columns: [user_id, brand_id, brand_count, total_interactions, tf]\n",
      "Index: []\n",
      "======================================================================\n",
      "idf > 1\n",
      "      brand_id     df        idf\n",
      "0            0  40579   2.346859\n",
      "1            1   1482   5.656067\n",
      "2            2      3  11.571595\n",
      "3            3      6  11.011979\n",
      "4            4      1  12.264742\n",
      "...        ...    ...        ...\n",
      "8439      8473   8588   3.899652\n",
      "8440      8474      7  10.878448\n",
      "8441      8475     76   8.614084\n",
      "8442      8476   5682   4.312655\n",
      "8443      8477    165   7.845902\n",
      "\n",
      "[8444 rows x 3 columns]\n",
      "   user_id  brand_id     tfidf\n",
      "0   328862      2661  0.346613\n",
      "1   328862      1049  0.011485\n",
      "2   328862      1647  0.063780\n",
      "3   328862      4953  0.092827\n",
      "4   328862      7622  0.118209\n",
      "        user_id                                       top_10_tfidf\n",
      "0             1  [2.1093608797482153, 0.8532460580929809, 0.612...\n",
      "1             2  [1.2985146869992235, 0.9498085204338002, 0.300...\n",
      "2             3  [0.82840763025819, 0.7725655555138775, 0.36971...\n",
      "3             4  [2.4117110134882167, 0.6777872943601424, 0.428...\n",
      "4             5  [0.2652259049949224, 0.25613463149856885, 0.24...\n",
      "...         ...                                                ...\n",
      "424165   424166  [1.2184705366346944, 0.77576810086554, 0.53000...\n",
      "424166   424167  [0.9039046372767459, 0.5821986664920394, 0.487...\n",
      "424167   424168  [0.28752022776015723, 0.2747520664725361, 0.20...\n",
      "424168   424169  [0.5198795112249264, 0.32008492757279183, 0.23...\n",
      "424169   424170  [3.6509346582253315, 1.0544282168312284, 0.258...\n",
      "\n",
      "[424170 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use brand_id\n",
    "user_brand_df = user_logs.copy()\n",
    "user_brand_df.drop(columns=['action_type', 'time_stamp', 'merchant_id', 'item_id', 'cat_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of brand_id for each user_id (Numerator of TF)\n",
    "user_brand_df['brand_count'] = user_brand_df.groupby(['user_id', 'brand_id'])['brand_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each user_id (Denominator of TF)\n",
    "user_brand_df['total_interactions'] = user_brand_df.groupby('user_id')['brand_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "user_brand_df['tf'] = user_brand_df['brand_count'] / user_brand_df['total_interactions']\n",
    "user_brand_df = user_brand_df.drop_duplicates(subset=['user_id', 'brand_id'])\n",
    "print(\"tf > 1\")\n",
    "print(user_brand_df[user_brand_df['tf'] > 1])\n",
    "print(\"=\"*70)\n",
    "# Step 5: Calculate the document frequency (df) for each brand_id\n",
    "df_brand_df = user_brand_df.groupby('brand_id')['user_id'].nunique().reset_index(name='df')\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = user_brand_df['user_id'].nunique()  # Total number of unique users\n",
    "df_brand_df['idf'] = df_brand_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "print(\"idf > 1\")\n",
    "print(df_brand_df[df_brand_df['idf'] > 1])\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "user_brand_df = user_brand_df.merge(df_brand_df[['brand_id', 'idf']], on='brand_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "user_brand_df['tfidf'] = user_brand_df['tf'] * user_brand_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "user_brand_df.drop(columns=['brand_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(user_brand_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per user_id\n",
    "n = 10  # Adjust this value as needed\n",
    "\n",
    "# Group by user_id and keep the top n TF-IDF values for each user\n",
    "grouped = (\n",
    "    user_brand_df.groupby('user_id')['tfidf']\n",
    "    .apply(lambda x: sorted(x, reverse=True)[:n])  # Sort and select top n\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'brand_user.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf > 1\n",
      "Empty DataFrame\n",
      "Columns: [user_id, item_id, item_count, total_interactions, tf]\n",
      "Index: []\n",
      "======================================================================\n",
      "idf > 1\n",
      "         item_id    df        idf\n",
      "0              1     1  12.264742\n",
      "1              2  1277   5.804838\n",
      "2              3    58   8.880352\n",
      "3              4    21   9.866847\n",
      "4              5     3  11.571595\n",
      "...          ...   ...        ...\n",
      "1090385  1113162    50   9.026064\n",
      "1090386  1113163    11  10.472983\n",
      "1090387  1113164     1  12.264742\n",
      "1090388  1113165     1  12.264742\n",
      "1090389  1113166    35   9.374371\n",
      "\n",
      "[1090390 rows x 3 columns]\n",
      "   user_id  item_id     tfidf\n",
      "0   328862   323294  0.025430\n",
      "1   328862   844400  0.027617\n",
      "2   328862   575153  0.102727\n",
      "3   328862   996875  0.027085\n",
      "4   328862  1086186  0.020590\n",
      "        user_id                                       top_20_tfidf\n",
      "0             1  [2.938813961148432, 0.8082934134510749, 0.6839...\n",
      "1             2  [0.48537673766426714, 0.4782818780807995, 0.41...\n",
      "2             3  [0.6125058033137332, 0.44935150919180367, 0.38...\n",
      "3             4  [1.6032494349289383, 0.7252855439314696, 0.723...\n",
      "4             5  [0.3342774436143631, 0.33374864607856436, 0.31...\n",
      "...         ...                                                ...\n",
      "424165   424166  [0.6833226264101191, 0.43393334687380924, 0.40...\n",
      "424166   424167  [1.4696835604138074, 1.3859222154046595, 0.661...\n",
      "424167   424168  [0.3413361792134656, 0.27578043218345616, 0.25...\n",
      "424168   424169  [0.41939036601497337, 0.2483550200744315, 0.24...\n",
      "424169   424170  [4.3545865141495135, 0.4768514323530869, 0.392...\n",
      "\n",
      "[424170 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use item_id\n",
    "user_item_df = user_logs.copy()\n",
    "user_item_df.drop(columns=['action_type', 'time_stamp', 'merchant_id', 'brand_id', 'cat_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of item_id for each user_id (Numerator of TF)\n",
    "user_item_df['item_count'] = user_item_df.groupby(['user_id', 'item_id'])['item_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each user_id (Denominator of TF)\n",
    "user_item_df['total_interactions'] = user_item_df.groupby('user_id')['item_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "user_item_df['tf'] = user_item_df['item_count'] / user_item_df['total_interactions']\n",
    "user_item_df = user_item_df.drop_duplicates(subset=['user_id', 'item_id'])\n",
    "print(\"tf > 1\")\n",
    "print(user_item_df[user_item_df['tf'] > 1])\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 5: Calculate the document frequency (df) for each item_id\n",
    "df_item_df = user_item_df.groupby('item_id')['user_id'].nunique().reset_index(name='df')\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = user_item_df['user_id'].nunique()  # Total number of unique users\n",
    "df_item_df['idf'] = df_item_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "print(\"idf > 1\")\n",
    "print(df_item_df[df_item_df['idf'] > 1])\n",
    "\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "user_item_df = user_item_df.merge(df_item_df[['item_id', 'idf']], on='item_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "user_item_df['tfidf'] = user_item_df['tf'] * user_item_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "user_item_df.drop(columns=['item_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(user_item_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per user_id\n",
    "n = 20  # Adjust this value as needed\n",
    "\n",
    "# Group by user_id and keep the top n TF-IDF values for each user\n",
    "grouped = (\n",
    "    user_item_df.groupby('user_id')['tfidf']\n",
    "    .apply(lambda x: sorted(x, reverse=True)[:n])  # Sort and select top n\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'item_user.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf > 1\n",
      "Empty DataFrame\n",
      "Columns: [user_id, merchant_id, merchant_count, total_interactions, tf]\n",
      "Index: []\n",
      "======================================================================\n",
      "idf > 1\n",
      "      merchant_id     df       idf\n",
      "0               1  30796  2.622717\n",
      "1               2    936  6.115206\n",
      "2               3   1136  5.921741\n",
      "3               4   1481  5.656742\n",
      "4               5   3652  4.754586\n",
      "...           ...    ...       ...\n",
      "4990         4991    227  7.528544\n",
      "4991         4992   2570  5.105839\n",
      "4992         4993   3986  4.667095\n",
      "4993         4994   2736  5.043272\n",
      "4994         4995   3017  4.945540\n",
      "\n",
      "[4995 rows x 3 columns]\n",
      "   user_id  merchant_id     tfidf\n",
      "0   328862         2882  0.346839\n",
      "1   328862         1253  0.034181\n",
      "2   328862          883  0.063774\n",
      "3   328862          420  0.085869\n",
      "4   328862         4605  0.118227\n",
      "        user_id                                        top_5_tfidf\n",
      "0             1  [2.109216555057508, 0.8532460580929809, 0.6127...\n",
      "1             2  [1.2983805393879055, 1.1421873734049512, 0.192...\n",
      "2             3  [1.0632388105052024, 0.7908850026624175, 0.438...\n",
      "3             4  [2.411417844321213, 0.6777872943601424, 0.4365...\n",
      "4             5  [0.3534801338159291, 0.27532557042919376, 0.26...\n",
      "...         ...                                                ...\n",
      "424165   424166  [1.212869568067083, 0.7893236458064395, 0.6076...\n",
      "424166   424167  [1.090589505771565, 0.9037748373803565, 0.4954...\n",
      "424167   424168  [0.2800964011696503, 0.27474029333250005, 0.20...\n",
      "424168   424169  [0.5198142732666843, 0.30546143008127197, 0.23...\n",
      "424169   424170  [3.6363932883056727, 1.054388213630887, 0.2589...\n",
      "\n",
      "[424170 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use merchant_id\n",
    "user_merchant_df = user_logs.copy()\n",
    "user_merchant_df.drop(columns=['action_type', 'time_stamp', 'brand_id', 'cat_id', 'item_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of merchant_id for each user_id (Numerator of TF)\n",
    "user_merchant_df['merchant_count'] = user_merchant_df.groupby(['user_id', 'merchant_id'])['merchant_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each user_id (Denominator of TF)\n",
    "user_merchant_df['total_interactions'] = user_merchant_df.groupby('user_id')['merchant_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "user_merchant_df['tf'] = user_merchant_df['merchant_count'] / user_merchant_df['total_interactions']\n",
    "user_merchant_df = user_merchant_df.drop_duplicates(subset=['user_id', 'merchant_id'])\n",
    "print(\"tf > 1\")\n",
    "print(user_merchant_df[user_merchant_df['tf'] > 1])\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 5: Calculate the document frequency (df) for each merchant_id\n",
    "df_merchant_df = user_merchant_df.groupby('merchant_id')['user_id'].nunique().reset_index(name='df')\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = user_merchant_df['user_id'].nunique()  # Total number of unique users\n",
    "df_merchant_df['idf'] = df_merchant_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "print(\"idf > 1\")\n",
    "print(df_merchant_df[df_merchant_df['idf'] > 1])\n",
    "\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "user_merchant_df = user_merchant_df.merge(df_merchant_df[['merchant_id', 'idf']], on='merchant_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "user_merchant_df['tfidf'] = user_merchant_df['tf'] * user_merchant_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "user_merchant_df.drop(columns=['merchant_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(user_merchant_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per user_id\n",
    "n = 5  # Adjust this value as needed\n",
    "\n",
    "# Group by user_id and keep the top n TF-IDF values for each user\n",
    "grouped = (\n",
    "    user_merchant_df.groupby('user_id')['tfidf']\n",
    "    .apply(lambda x: sorted(x, reverse=True)[:n])  # Sort and select top n\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'merchant_user.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seller-brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf > 1\n",
      "Empty DataFrame\n",
      "Columns: [merchant_id, brand_id, brand_count, total_interactions, tf]\n",
      "Index: []\n",
      "======================================================================\n",
      "idf > 1\n",
      "      brand_id  df       idf\n",
      "1            1   1  7.823046\n",
      "2            2   1  7.823046\n",
      "3            3   1  7.823046\n",
      "4            4   1  7.823046\n",
      "5            5   1  7.823046\n",
      "...        ...  ..       ...\n",
      "8439      8473  12  5.951243\n",
      "8440      8474   2  7.417580\n",
      "8441      8475   2  7.417580\n",
      "8442      8476  13  5.877135\n",
      "8443      8477   2  7.417580\n",
      "\n",
      "[8443 rows x 3 columns]\n",
      "   merchant_id  brand_id     tfidf\n",
      "0         2882      2661  7.412854\n",
      "1         1253      1049  1.303665\n",
      "2          883      1647  7.817731\n",
      "3          420      4953  4.884490\n",
      "4         4605      7622  6.717112\n",
      "      merchant_id                                       top_10_tfidf\n",
      "0               1  [7.253192437843725, 0.16313197455451023, 6.281...\n",
      "1               2        [5.857305296983322, 0.00016188842475962936]\n",
      "2               3         [7.811214817879197, 7.255906523725544e-05]\n",
      "3               4  [7.777709123146853, 0.008463215913337369, 6.17...\n",
      "4               5        [7.814450856031168, 5.2712052855617235e-05]\n",
      "...           ...                                                ...\n",
      "4990         4991         [7.79955288136198, 0.00014408312879319866]\n",
      "4991         4992            [7.81176986118497, 6.9154917682524e-05]\n",
      "4992         4993          [7.81317554352268, 6.053369832385454e-05]\n",
      "4993         4994  [3.093970458484001, 1.6367001603074305, 1.6146...\n",
      "4994         4995  [4.894311973124055, 0.8517495996248966, 0.2042...\n",
      "\n",
      "[4995 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use brand_id and merchant_id as basis\n",
    "merchant_brand_df = user_logs.copy()\n",
    "merchant_brand_df.drop(columns=['action_type', 'time_stamp', 'user_id', 'item_id', 'cat_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of brand_id for each merchant_id (Numerator of TF)\n",
    "merchant_brand_df['brand_count'] = merchant_brand_df.groupby(['merchant_id', 'brand_id'])['brand_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each merchant_id (Denominator of TF)\n",
    "merchant_brand_df['total_interactions'] = merchant_brand_df.groupby('merchant_id')['brand_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "merchant_brand_df['tf'] = merchant_brand_df['brand_count'] / merchant_brand_df['total_interactions']\n",
    "merchant_brand_df = merchant_brand_df.drop_duplicates(subset=['merchant_id', 'brand_id'])\n",
    "print(\"tf > 1\")\n",
    "print(merchant_brand_df[merchant_brand_df['tf'] > 1])\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 5: Calculate the document frequency (df) for each brand_id\n",
    "df_brand_df = merchant_brand_df.groupby('brand_id')['merchant_id'].nunique().reset_index(name='df')\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = merchant_brand_df['merchant_id'].nunique()  # Total number of unique merchants\n",
    "df_brand_df['idf'] = df_brand_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "print(\"idf > 1\")\n",
    "print(df_brand_df[df_brand_df['idf'] > 1])\n",
    "\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "merchant_brand_df = merchant_brand_df.merge(df_brand_df[['brand_id', 'idf']], on='brand_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "merchant_brand_df['tfidf'] = merchant_brand_df['tf'] * merchant_brand_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "merchant_brand_df.drop(columns=['brand_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(merchant_brand_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per merchant_id\n",
    "n = 10  # Adjust this value as needed\n",
    "\n",
    "# Group by merchant_id and keep the top n TF-IDF values for each merchant\n",
    "grouped = (\n",
    "    merchant_brand_df.groupby('merchant_id')['tfidf']\n",
    "    .apply(lambda x: sorted(x, reverse=True)[:n])  # Sort and select top n\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'merchant_brand.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seller-Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf > 1\n",
      "Empty DataFrame\n",
      "Columns: [item_id, merchant_id, item_count, total_interactions, tf]\n",
      "Index: []\n",
      "======================================================================\n",
      "idf > 1\n",
      "         item_id  df       idf\n",
      "0              1   1  7.823046\n",
      "1              2   1  7.823046\n",
      "2              3   1  7.823046\n",
      "3              4   1  7.823046\n",
      "4              5   1  7.823046\n",
      "...          ...  ..       ...\n",
      "1090385  1113162   1  7.823046\n",
      "1090386  1113163   1  7.823046\n",
      "1090387  1113164   1  7.823046\n",
      "1090388  1113165   1  7.823046\n",
      "1090389  1113166   1  7.823046\n",
      "\n",
      "[1090390 rows x 3 columns]\n",
      "   item_id  merchant_id     tfidf\n",
      "0   323294         2882  0.011632\n",
      "1   844400         2882  0.002492\n",
      "2   575153         2882  0.009139\n",
      "3   996875         2882  0.004985\n",
      "4  1086186         1253  0.017328\n",
      "      merchant_id                                       top_20_tfidf\n",
      "0               1  [0.07393070962205957, 0.06952485454005852, 0.0...\n",
      "1               2  [1.8279068801474403, 0.5477121698636734, 0.316...\n",
      "2               3  [2.7181016348470206, 0.4850583983840167, 0.464...\n",
      "3               4  [1.4507643960273922, 0.6775271224502926, 0.612...\n",
      "4               5  [0.9110333761033526, 0.595896044746847, 0.4507...\n",
      "...           ...                                                ...\n",
      "4990         4991  [5.309334190324722, 0.8104957060451455, 0.2584...\n",
      "4991         4992  [0.9584301937077403, 0.6449671421186206, 0.594...\n",
      "4992         4993  [1.24361584200361, 0.8268839020024003, 0.55491...\n",
      "4993         4994  [0.43948266709544687, 0.24768531816072872, 0.2...\n",
      "4994         4995  [2.1422724520024894, 0.5876661784676089, 0.524...\n",
      "\n",
      "[4995 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use merchant_id and item_id\n",
    "merchant_item_df = user_logs.copy()\n",
    "merchant_item_df.drop(columns=['action_type', 'time_stamp', 'user_id', 'brand_id', 'cat_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of item_id for each merchant_id (Numerator of TF)\n",
    "merchant_item_df['item_count'] = merchant_item_df.groupby(['merchant_id', 'item_id'])['item_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each merchant_id (Denominator of TF)\n",
    "merchant_item_df['total_interactions'] = merchant_item_df.groupby('merchant_id')['item_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "merchant_item_df['tf'] = merchant_item_df['item_count'] / merchant_item_df['total_interactions']\n",
    "merchant_item_df = merchant_item_df.drop_duplicates(subset=['merchant_id', 'item_id'])\n",
    "print(\"tf > 1\")\n",
    "print(merchant_item_df[merchant_item_df['tf'] > 1])\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 5: Calculate the document frequency (df) for each item_id\n",
    "df_item_df = merchant_item_df.groupby('item_id')['merchant_id'].nunique().reset_index(name='df')\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = merchant_item_df['merchant_id'].nunique()  # Total number of unique merchants\n",
    "df_item_df['idf'] = df_item_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "print(\"idf > 1\")\n",
    "print(df_item_df[df_item_df['idf'] > 1])\n",
    "\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "merchant_item_df = merchant_item_df.merge(df_item_df[['item_id', 'idf']], on='item_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "merchant_item_df['tfidf'] = merchant_item_df['tf'] * merchant_item_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "merchant_item_df.drop(columns=['item_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(merchant_item_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per merchant_id\n",
    "n = 20  # Adjust this value as needed\n",
    "\n",
    "# Group by merchant_id and keep the top n TF-IDF values for each merchant\n",
    "grouped = (\n",
    "    merchant_item_df.groupby('merchant_id')['tfidf']\n",
    "    .apply(lambda x: sorted(x, reverse=True)[:n])  # Sort and select top n\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'merchant_item.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seller-Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf > 1\n",
      "Empty DataFrame\n",
      "Columns: [cat_id, merchant_id, cat_count, total_interactions, tf]\n",
      "Index: []\n",
      "======================================================================\n",
      "idf > 1\n",
      "      cat_id   df       idf\n",
      "0          1   19  5.520460\n",
      "1          2  276  2.892175\n",
      "2          3   10  6.118297\n",
      "3          4   15  5.743604\n",
      "4          5   66  4.311500\n",
      "...      ...  ...       ...\n",
      "1653    1667    1  7.823046\n",
      "1654    1668   69  4.267697\n",
      "1655    1669    3  7.129898\n",
      "1656    1670   17  5.625821\n",
      "1657    1671    9  6.213608\n",
      "\n",
      "[1658 rows x 3 columns]\n",
      "   cat_id  merchant_id     tfidf\n",
      "0     833         2882  0.046024\n",
      "1    1271         2882  0.535697\n",
      "2    1271         1253  0.581464\n",
      "3    1467         2882  0.890357\n",
      "4    1095          883  0.561572\n",
      "      merchant_id                                       top_10_tfidf\n",
      "0               1  [0.5800430706645079, 0.5065708162286712, 0.318...\n",
      "1               2  [0.952426598072902, 0.8042220890388974, 0.2525...\n",
      "2               3  [2.1449311506830266, 0.23788666660482732, 0.04...\n",
      "3               4  [2.6104258954595196, 0.5939524089374005, 0.036...\n",
      "4               5  [1.0074621686830074, 0.3134467597730722, 0.224...\n",
      "...           ...                                                ...\n",
      "4990         4991         [2.4198590834567213, 0.005325261427299552]\n",
      "4991         4992         [3.9802019975761094, 0.031947061396535865]\n",
      "4992         4993       [2.5601758616527555, 0.00026938836872648404]\n",
      "4993         4994  [0.42168367897028963, 0.34122826426560426, 0.2...\n",
      "4994         4995  [1.8463271075948506, 0.32586625110192247, 0.23...\n",
      "\n",
      "[4995 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use merchant_id and cat_id\n",
    "merchant_cat_df = user_logs.copy()\n",
    "merchant_cat_df.drop(columns=['action_type', 'time_stamp', 'user_id', 'brand_id', 'item_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of cat_id for each merchant_id (Numerator of TF)\n",
    "merchant_cat_df['cat_count'] = merchant_cat_df.groupby(['merchant_id', 'cat_id'])['cat_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each merchant_id (Denominator of TF)\n",
    "merchant_cat_df['total_interactions'] = merchant_cat_df.groupby('merchant_id')['cat_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "merchant_cat_df['tf'] = merchant_cat_df['cat_count'] / merchant_cat_df['total_interactions']\n",
    "merchant_cat_df = merchant_cat_df.drop_duplicates(subset=['merchant_id', 'cat_id'])\n",
    "print(\"tf > 1\")\n",
    "print(merchant_cat_df[merchant_cat_df['tf'] > 1])\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 5: Calculate the document frequency (df) for each cat_id\n",
    "df_cat_df = merchant_cat_df.groupby('cat_id')['merchant_id'].nunique().reset_index(name='df')\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = merchant_cat_df['merchant_id'].nunique()  # Total number of unique merchants\n",
    "df_cat_df['idf'] = df_cat_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "print(\"idf > 1\")\n",
    "print(df_cat_df[df_cat_df['idf'] > 1])\n",
    "\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "merchant_cat_df = merchant_cat_df.merge(df_cat_df[['cat_id', 'idf']], on='cat_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "merchant_cat_df['tfidf'] = merchant_cat_df['tf'] * merchant_cat_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "merchant_cat_df.drop(columns=['cat_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(merchant_cat_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per merchant_id\n",
    "n = 10  # Adjust this value as needed\n",
    "\n",
    "# Group by merchant_id and keep the top n TF-IDF values for each merchant\n",
    "grouped = (\n",
    "    merchant_cat_df.groupby('merchant_id')['tfidf']\n",
    "    .apply(lambda x: sorted(x, reverse=True)[:n])  # Sort and select top n\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'merchant_cat.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Merchant Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134844\n",
      "54925330\n"
     ]
    }
   ],
   "source": [
    "# Filter\n",
    "user_merchant_df = user_logs.copy()\n",
    "user_merchant_df.drop(columns=['action_type', 'time_stamp'], inplace=True)\n",
    "sampled_df = pd.read_csv('train_df_sampled_X.csv')\n",
    "sampled_df['user_id'] = sampled_df['user_id'].astype(np.int32)\n",
    "sampled_df['merchant_id'] = sampled_df['merchant_id'].astype(np.int16)\n",
    "user_merchant_df = user_merchant_df.merge(sampled_df, on=['user_id', 'merchant_id'], how='inner')\n",
    "print(len(user_merchant_df))\n",
    "print(len(user_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104345\n"
     ]
    }
   ],
   "source": [
    "print(len(sampled_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Merchant Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  cat_id  merchant_id     tfidf\n",
      "0   356311    1129         3205  7.794258\n",
      "1   153790     898         1346  8.000110\n",
      "2    26516     602         2403  7.726817\n",
      "3   422265    1074         1273  8.722245\n",
      "4   255390     611         4585  5.376644\n",
      "        user_id  merchant_id   \n",
      "0             1         1019  \\\n",
      "1             6         1356   \n",
      "2            14          361   \n",
      "3            16         1435   \n",
      "4            17         1115   \n",
      "...         ...          ...   \n",
      "104340   424155         1394   \n",
      "104341   424157          798   \n",
      "104342   424163         3826   \n",
      "104343   424164          606   \n",
      "104344   424167         1200   \n",
      "\n",
      "                                              top_5_tfidf  \n",
      "0                                     [7.022858502535675]  \n",
      "1                                      [8.78286927344915]  \n",
      "2                                     [6.819259547294435]  \n",
      "3                                      [6.71127090923034]  \n",
      "4       [3.6699608402064086, 2.9171112474590464, 0.338...  \n",
      "...                                                   ...  \n",
      "104340                                [9.252872902694886]  \n",
      "104341                                 [7.26499855454054]  \n",
      "104342                               [7.7712683617706695]  \n",
      "104343  [2.966283080983155, 2.2521727366405244, 0.3612...  \n",
      "104344                                [7.161008841016492]  \n",
      "\n",
      "[104345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use user_id - merchant_id pairs as the basis for cat_id\n",
    "user_merchant_cat_df = user_merchant_df.copy()\n",
    "user_merchant_cat_df.drop(columns=['brand_id', 'item_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of cat_id for each user_id - merchant_id pair (Numerator of TF)\n",
    "user_merchant_cat_df['cat_count'] = user_merchant_cat_df.groupby(['user_id', 'merchant_id', 'cat_id'])['cat_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each user_id - merchant_id pair (Denominator of TF)\n",
    "user_merchant_cat_df['total_interactions'] = user_merchant_cat_df.groupby(['user_id', 'merchant_id'])['cat_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "user_merchant_cat_df['tf'] = user_merchant_cat_df['cat_count'] / user_merchant_cat_df['total_interactions']\n",
    "user_merchant_cat_df = user_merchant_cat_df.drop_duplicates(subset=['user_id', 'merchant_id', 'cat_id'])\n",
    "\n",
    "# Step 5: Calculate the document frequency (df) for each cat_id\n",
    "# Count unique user_id - merchant_id pairs for each cat_id\n",
    "df_cat_df = (\n",
    "    user_merchant_cat_df.groupby('cat_id')[['user_id', 'merchant_id']]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    ")\n",
    "df_cat_df['df'] = df_cat_df[['user_id', 'merchant_id']].min(axis=1)\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = user_merchant_cat_df.groupby(['user_id', 'merchant_id']).ngroups  # Total unique user_id - merchant_id pairs\n",
    "df_cat_df['idf'] = df_cat_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "user_merchant_cat_df = user_merchant_cat_df.merge(df_cat_df[['cat_id', 'idf']], on='cat_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "user_merchant_cat_df['tfidf'] = user_merchant_cat_df['tf'] * user_merchant_cat_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "user_merchant_cat_df.drop(columns=['cat_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(user_merchant_cat_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per user_id - merchant_id pair\n",
    "n = 5  # Adjust this value as needed\n",
    "\n",
    "# Group by user_id - merchant_id and keep the top n TF-IDF values for each pair\n",
    "grouped = (\n",
    "    user_merchant_cat_df.groupby(['user_id', 'merchant_id'])['tfidf']\n",
    "    .apply(lambda x: x.nlargest(n).tolist())  # Use nlargest for efficiency\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'user_merchant_cat.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Merchant Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  merchant_id  brand_id      tfidf\n",
      "0   356311         3205      2270  10.862311\n",
      "1   153790         1346      7995   9.157563\n",
      "2    26516         2403      2373   4.344924\n",
      "3    26516         2403      8417   6.517386\n",
      "4   422265         1273      2753  10.862311\n",
      "        user_id  merchant_id           top_5_tfidf\n",
      "0             1         1019  [10.862310815128986]\n",
      "1             6         1356   [10.16916363456904]\n",
      "2            14          361  [10.862310815128986]\n",
      "3            16         1435  [10.862310815128986]\n",
      "4            17         1115  [10.862310815128986]\n",
      "...         ...          ...                   ...\n",
      "104340   424155         1394   [8.916400666073672]\n",
      "104341   424157          798  [10.862310815128986]\n",
      "104342   424163         3826  [10.456845707020822]\n",
      "104343   424164          606  [10.862310815128986]\n",
      "104344   424167         1200    [8.29736145766745]\n",
      "\n",
      "[104345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use user_id - merchant_id pairs as the basis for brand_id\n",
    "user_merchant_brand_df = user_merchant_df.copy()\n",
    "user_merchant_brand_df.drop(columns=['cat_id', 'item_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of brand_id for each user_id - merchant_id pair (Numerator of TF)\n",
    "user_merchant_brand_df['brand_count'] = user_merchant_brand_df.groupby(['user_id', 'merchant_id', 'brand_id'])['brand_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each user_id - merchant_id pair (Denominator of TF)\n",
    "user_merchant_brand_df['total_interactions'] = user_merchant_brand_df.groupby(['user_id', 'merchant_id'])['brand_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "user_merchant_brand_df['tf'] = user_merchant_brand_df['brand_count'] / user_merchant_brand_df['total_interactions']\n",
    "user_merchant_brand_df = user_merchant_brand_df.drop_duplicates(subset=['user_id', 'merchant_id', 'brand_id'])\n",
    "\n",
    "# Step 5: Calculate the document frequency (df) for each brand_id\n",
    "# Count unique user_id - merchant_id pairs for each brand_id\n",
    "df_brand_df = (\n",
    "    user_merchant_brand_df.groupby('brand_id')[['user_id', 'merchant_id']]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    ")\n",
    "df_brand_df['df'] = df_brand_df[['user_id', 'merchant_id']].min(axis=1)\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = user_merchant_brand_df.groupby(['user_id', 'merchant_id']).ngroups  # Total unique user_id - merchant_id pairs\n",
    "df_brand_df['idf'] = df_brand_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "user_merchant_brand_df = user_merchant_brand_df.merge(df_brand_df[['brand_id', 'idf']], on='brand_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "user_merchant_brand_df['tfidf'] = user_merchant_brand_df['tf'] * user_merchant_brand_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "user_merchant_brand_df.drop(columns=['brand_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(user_merchant_brand_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per user_id - merchant_id pair\n",
    "n = 5  # Adjust this value as needed\n",
    "\n",
    "# Group by user_id - merchant_id and keep the top n TF-IDF values for each pair\n",
    "grouped = (\n",
    "    user_merchant_brand_df.groupby(['user_id', 'merchant_id'])['tfidf']\n",
    "    .apply(lambda x: x.nlargest(n).tolist())  # Use nlargest for efficiency\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'user_merchant_brand.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Merchant Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  merchant_id     tfidf\n",
      "0   356311   758374         3205  4.023078\n",
      "1   356311   413046         3205  0.804616\n",
      "2   356311   113205         3205  1.609231\n",
      "3   356311   998103         3205  2.011539\n",
      "4   356311   830436         3205  1.206923\n",
      "        user_id  merchant_id   \n",
      "0             1         1019  \\\n",
      "1             6         1356   \n",
      "2            14          361   \n",
      "3            16         1435   \n",
      "4            17         1115   \n",
      "...         ...          ...   \n",
      "104340   424155         1394   \n",
      "104341   424157          798   \n",
      "104342   424163         3826   \n",
      "104343   424164          606   \n",
      "104344   424167         1200   \n",
      "\n",
      "                                              top_5_tfidf  \n",
      "0                                    [10.862310815128986]  \n",
      "1                                    [10.862310815128986]  \n",
      "2       [1.9749656027507247, 1.9749656027507247, 1.481...  \n",
      "3       [3.9499312055014495, 2.9624484041260866, 0.987...  \n",
      "4       [5.974270948320942, 3.2586932445386956, 0.5431...  \n",
      "...                                                   ...  \n",
      "104340                               [10.862310815128986]  \n",
      "104341                               [10.862310815128986]  \n",
      "104342                               [10.862310815128986]  \n",
      "104343  [2.858502846086575, 1.715101707651945, 1.71510...  \n",
      "104344                               [10.862310815128986]  \n",
      "\n",
      "[104345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# Step 1: Modify to use user_id - merchant_id pairs as the basis for item_id\n",
    "user_merchant_item_df = user_merchant_df.copy()\n",
    "user_merchant_item_df.drop(columns=['cat_id', 'brand_id'], inplace=True)\n",
    "\n",
    "# Step 2: Count occurrences of item_id for each user_id - merchant_id pair (Numerator of TF)\n",
    "user_merchant_item_df['item_count'] = user_merchant_item_df.groupby(['user_id', 'merchant_id', 'item_id'])['item_id'].transform('count')\n",
    "\n",
    "# Step 3: Calculate total interactions for each user_id - merchant_id pair (Denominator of TF)\n",
    "user_merchant_item_df['total_interactions'] = user_merchant_item_df.groupby(['user_id', 'merchant_id'])['item_id'].transform('count')\n",
    "\n",
    "# Step 4: Calculate TF (Term Frequency)\n",
    "user_merchant_item_df['tf'] = user_merchant_item_df['item_count'] / user_merchant_item_df['total_interactions']\n",
    "user_merchant_item_df = user_merchant_item_df.drop_duplicates(subset=['user_id', 'merchant_id', 'item_id'])\n",
    "\n",
    "# Step 5: Calculate the document frequency (df) for each item_id\n",
    "# Count unique user_id - merchant_id pairs for each item_id\n",
    "df_item_df = (\n",
    "    user_merchant_item_df.groupby('item_id')[['user_id', 'merchant_id']]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    ")\n",
    "df_item_df['df'] = df_item_df[['user_id', 'merchant_id']].min(axis=1)\n",
    "\n",
    "# Step 6: Calculate IDF (Inverse Document Frequency)\n",
    "N = user_merchant_item_df.groupby(['user_id', 'merchant_id']).ngroups  # Total unique user_id - merchant_id pairs\n",
    "df_item_df['idf'] = df_item_df['df'].apply(lambda x: log(N / (x + 1)))  # IDF formula\n",
    "\n",
    "# Step 7: Merge IDF back into the original DataFrame\n",
    "user_merchant_item_df = user_merchant_item_df.merge(df_item_df[['item_id', 'idf']], on='item_id', how='left')\n",
    "\n",
    "# Step 8: Calculate TF-IDF\n",
    "user_merchant_item_df['tfidf'] = user_merchant_item_df['tf'] * user_merchant_item_df['idf']\n",
    "\n",
    "# Clean up unnecessary columns\n",
    "user_merchant_item_df.drop(columns=['item_count', 'total_interactions', 'tf', 'idf'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(user_merchant_item_df.head(5))\n",
    "\n",
    "# Set the number of top tfidf values you want per user_id - merchant_id pair\n",
    "n = 5  # Adjust this value as needed\n",
    "\n",
    "# Group by user_id - merchant_id and keep the top n TF-IDF values for each pair\n",
    "grouped = (\n",
    "    user_merchant_item_df.groupby(['user_id', 'merchant_id'])['tfidf']\n",
    "    .apply(lambda x: x.nlargest(n).tolist())  # Use nlargest for efficiency\n",
    "    .reset_index(name=f'top_{n}_tfidf')  # Reset index and rename column\n",
    ")\n",
    "\n",
    "# Save the output if needed\n",
    "grouped.to_csv(f'user_merchant_item.csv', index=False)  # Optional: save to a file\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

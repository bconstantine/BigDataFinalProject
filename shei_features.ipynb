{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('data_format1/data_format1/train_format1.csv')\n",
    "testing_data = pd.read_csv('data_format1/data_format1/test_format1.csv')\n",
    "user_demo = pd.read_csv('data_format1/data_format1/user_info_format1.csv')\n",
    "user_logs = pd.read_csv('data_format1/data_format1/user_log_format1.csv')\n",
    "testing_data.drop('prob', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_range', 'gender']\n",
      "['brand_id']\n"
     ]
    }
   ],
   "source": [
    "# Check if any column in the tables contains any empty data\n",
    "print(user_demo.columns[user_demo.isnull().any()].tolist())\n",
    "print(user_logs.columns[user_logs.isnull().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuas\\AppData\\Local\\Temp\\ipykernel_1640\\3035380006.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  user_logs['brand_id'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "user_logs['user_id'] = user_logs['user_id'].astype(np.int32)\n",
    "user_logs['item_id'] = user_logs['item_id'].astype(np.int32)\n",
    "user_logs['cat_id'] = user_logs['cat_id'].astype(np.int16)\n",
    "user_logs['seller_id'] = user_logs['seller_id'].astype(np.int16)\n",
    "user_logs.rename(columns={'seller_id' : 'merchant_id'}, inplace=True)\n",
    "user_logs['brand_id'].fillna(0, inplace=True)\n",
    "user_logs['brand_id'] = user_logs['brand_id'].astype(np.int16)\n",
    "user_logs['time_stamp'] = (pd.to_datetime(user_logs['time_stamp'], format='%m%d') - pd.to_datetime(user_logs['time_stamp'].min(), format='%m%d')).dt.days\n",
    "user_logs['time_stamp'] = user_logs['time_stamp'].astype(np.int16)\n",
    "user_logs['action_type'] = user_logs['action_type'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuas\\AppData\\Local\\Temp\\ipykernel_1640\\2765511242.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  user_demo['age_range'].fillna(0, inplace=True)\n",
      "C:\\Users\\chuas\\AppData\\Local\\Temp\\ipykernel_1640\\2765511242.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  user_demo['gender'].fillna(2, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "user_demo['age_range'].fillna(0, inplace=True)\n",
    "user_demo['gender'].fillna(2, inplace=True)\n",
    "user_demo['age_range'] = user_demo['age_range'].astype(np.int8)\n",
    "user_demo['gender'] = user_demo['gender'].astype(np.int8)\n",
    "user_logs['time_period'] = user_logs['time_stamp'] // 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = training_data.merge(user_demo, on='user_id', how='left')\n",
    "df_test = testing_data.merge(user_demo, on='user_id', how='left')\n",
    "\n",
    "df_train = df_train.merge(\n",
    "    user_logs[['user_id', 'merchant_id', 'item_id', 'cat_id', 'brand_id','time_stamp','time_period']].drop_duplicates(),\n",
    "    on=['user_id', 'merchant_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_test = df_test.merge(\n",
    "    user_logs[['user_id', 'merchant_id', 'item_id', 'cat_id', 'brand_id','time_stamp','time_period']].drop_duplicates(),\n",
    "    on=['user_id', 'merchant_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_train['type'] = 'train'\n",
    "df_test['type'] = 'test'\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping for easy aggregration\n",
    "users = user_logs.groupby('user_id')\n",
    "merchants = user_logs.groupby('merchant_id')\n",
    "brands = user_logs.groupby('brand_id')\n",
    "categories = user_logs.groupby('cat_id')\n",
    "items = user_logs.groupby('item_id')\n",
    "users_merchants = user_logs.groupby(['user_id', 'merchant_id'])\n",
    "users_brands = user_logs.groupby(['user_id', 'brand_id'])\n",
    "users_categories = user_logs.groupby(['user_id', 'cat_id'])\n",
    "merchant_brands = user_logs.groupby(['merchant_id', 'brand_id'])\n",
    "merchant_categories = user_logs.groupby(['merchant_id', 'cat_id'])\n",
    "user_logs['time_period'] = user_logs['time_stamp'] // 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for the age_range column\n",
    "age_dummies = pd.get_dummies(user_demo[['user_id', 'age_range']], columns=['age_range'], prefix='age')\n",
    "\n",
    "df = df.merge(age_dummies, on='user_id', how='left')\n",
    "df_train = df_train.merge(age_dummies, on='user_id', how='left')\n",
    "df.drop('age_range', axis=1, inplace=True)\n",
    "df_train.drop('age_range', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Count and Action Count/Ratio Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Count of Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total number of unique values for a given user\n",
    "to_merge = users.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_user', \n",
    "    'cat_id': 'categories_user',\n",
    "    'merchant_id': 'merchants_user',\n",
    "    'brand_id': 'brands_user',\n",
    "    'time_stamp': 'dates_user',\n",
    "    'time_period': 'periods_user',\n",
    "    'action_type': 'action_types_user'\n",
    "})\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# Count total number of unique values for a given merchant\n",
    "to_merge = merchants.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_merchant', \n",
    "    'cat_id': 'categories_merchant',\n",
    "    'user_id': 'users_merchant',\n",
    "    'brand_id': 'brands_merchant',\n",
    "    'time_stamp': 'dates_merchant',\n",
    "    'time_period': 'periods_merchant',\n",
    "    'action_type': 'action_types_merchant'\n",
    "})\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# Count total number of unique values for a given user and merchant\n",
    "to_merge = users_merchants.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_user_merchant', \n",
    "    'cat_id': 'categories_user_merchant',\n",
    "    'brand_id': 'brands_user_merchant',\n",
    "    'time_stamp': 'dates_user_merchant',\n",
    "    'time_period': 'periods_user_merchant',\n",
    "    'action_type': 'action_types_user_merchant'\n",
    "})\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# Count total number of unique values for a given item\n",
    "to_merge = items.nunique().reset_index().rename(columns={\n",
    "    'user_id': 'users_item',\n",
    "    'cat_id': 'categories_item',\n",
    "    'merchant_id': 'merchants_item',\n",
    "    'brand_id': 'brands_item',\n",
    "    'time_stamp': 'dates_item',\n",
    "    'time_period': 'periods_item',\n",
    "    'action_type': 'action_types_item'\n",
    "})\n",
    "df = df.merge(to_merge, on='item_id', how='left')\n",
    "\n",
    "# Count total number of unique values for a given category\n",
    "to_merge = categories.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_category',\n",
    "    'user_id': 'users_category',\n",
    "    'merchant_id': 'merchants_category',\n",
    "    'brand_id': 'brands_category',\n",
    "    'time_stamp': 'dates_category',\n",
    "    'time_period': 'periods_category',\n",
    "    'action_type': 'action_types_category'\n",
    "})\n",
    "df = df.merge(to_merge, on='cat_id', how='left')\n",
    "\n",
    "# Count total number of unique values for a given brand\n",
    "to_merge = brands.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_brand',\n",
    "    'user_id': 'users_brand',\n",
    "    'merchant_id': 'merchants_brand',\n",
    "    'cat_id': 'categories_brand',\n",
    "    'time_stamp': 'dates_brand',\n",
    "    'time_period': 'periods_brand',\n",
    "    'action_type': 'action_types_brand'\n",
    "})\n",
    "df = df.merge(to_merge, on='brand_id', how='left')\n",
    "\n",
    "# Count total number of unique values for a given user and brand\n",
    "to_merge = users_brands.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_user_brand',\n",
    "    'cat_id': 'categories_user_brand',\n",
    "    'merchant_id': 'merchants_user_brand',\n",
    "    'time_stamp': 'dates_user_brand',\n",
    "    'time_period': 'periods_user_brand',\n",
    "    'action_type': 'action_types_user_brand'\n",
    "})\n",
    "df = df.merge(to_merge, on=['user_id', 'brand_id'], how='left')\n",
    "\n",
    "# Count total number of unique values for a given user and category\n",
    "to_merge = users_categories.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_user_category',\n",
    "    'merchant_id': 'merchants_user_category',\n",
    "    'brand_id': 'brands_user_category',\n",
    "    'time_stamp': 'dates_user_category',\n",
    "    'time_period': 'periods_user_category',\n",
    "    'action_type': 'action_types_user_category'\n",
    "})\n",
    "df = df.merge(to_merge, on=['user_id', 'cat_id'], how='left')\n",
    "\n",
    "# Count total number of unique values for a given merchant and brand\n",
    "to_merge = merchant_brands.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_merchant_brand',\n",
    "    'cat_id': 'categories_merchant_brand',\n",
    "    'user_id': 'users_merchant_brand',\n",
    "    'time_stamp': 'dates_merchant_brand',\n",
    "    'time_period': 'periods_merchant_brand',\n",
    "    'action_type': 'action_types_merchant_brand'\n",
    "})\n",
    "df = df.merge(to_merge, on=['merchant_id', 'brand_id'], how='left')\n",
    "\n",
    "# Count total number of unique values for a given merchant and category\n",
    "to_merge = merchant_categories.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'items_merchant_category',\n",
    "    'user_id': 'users_merchant_category',\n",
    "    'brand_id': 'brands_merchant_category',\n",
    "    'time_stamp': 'dates_merchant_category',\n",
    "    'time_period': 'periods_merchant_category',\n",
    "    'action_type': 'action_types_merchant_category'\n",
    "})\n",
    "df = df.merge(to_merge, on=['merchant_id', 'cat_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Action Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>item_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>time_period</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>purchases_user_cat</th>\n",
       "      <th>favourites_user_cat</th>\n",
       "      <th>clicks_merchant_brand</th>\n",
       "      <th>carts_merchant_brand</th>\n",
       "      <th>purchases_merchant_brand</th>\n",
       "      <th>favourites_merchant_brand</th>\n",
       "      <th>clicks_merchant_cat</th>\n",
       "      <th>carts_merchant_cat</th>\n",
       "      <th>purchases_merchant_cat</th>\n",
       "      <th>favourites_merchant_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>757713</td>\n",
       "      <td>821</td>\n",
       "      <td>6268</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14870</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>961</td>\n",
       "      <td>2790</td>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>718096</td>\n",
       "      <td>1142</td>\n",
       "      <td>6268</td>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14870</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>961</td>\n",
       "      <td>1421</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>757713</td>\n",
       "      <td>821</td>\n",
       "      <td>6268</td>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14870</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>961</td>\n",
       "      <td>2790</td>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>613698</td>\n",
       "      <td>821</td>\n",
       "      <td>6268</td>\n",
       "      <td>163</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14870</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>961</td>\n",
       "      <td>2790</td>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>757713</td>\n",
       "      <td>821</td>\n",
       "      <td>6268</td>\n",
       "      <td>181</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14870</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>961</td>\n",
       "      <td>2790</td>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label  gender  item_id  cat_id  brand_id  time_stamp  \\\n",
       "0    34176         3906    0.0       0   757713     821      6268         183   \n",
       "1    34176         3906    0.0       0   718096    1142      6268         173   \n",
       "2    34176         3906    0.0       0   757713     821      6268         173   \n",
       "3    34176         3906    0.0       0   613698     821      6268         163   \n",
       "4    34176         3906    0.0       0   757713     821      6268         181   \n",
       "\n",
       "   time_period   type  ...  purchases_user_cat  favourites_user_cat  \\\n",
       "0            5  train  ...                   1                    1   \n",
       "1            5  train  ...                   0                    2   \n",
       "2            5  train  ...                   1                    1   \n",
       "3            5  train  ...                   1                    1   \n",
       "4            5  train  ...                   1                    1   \n",
       "\n",
       "   clicks_merchant_brand  carts_merchant_brand  purchases_merchant_brand  \\\n",
       "0                  14870                     1                       410   \n",
       "1                  14870                     1                       410   \n",
       "2                  14870                     1                       410   \n",
       "3                  14870                     1                       410   \n",
       "4                  14870                     1                       410   \n",
       "\n",
       "   favourites_merchant_brand  clicks_merchant_cat  carts_merchant_cat  \\\n",
       "0                        961                 2790                   6   \n",
       "1                        961                 1421                   4   \n",
       "2                        961                 2790                   6   \n",
       "3                        961                 2790                   6   \n",
       "4                        961                 2790                   6   \n",
       "\n",
       "   purchases_merchant_cat  favourites_merchant_cat  \n",
       "0                     103                      207  \n",
       "1                      33                       81  \n",
       "2                     103                      207  \n",
       "3                     103                      207  \n",
       "4                     103                      207  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_list = ['user', 'merchant', 'brand', 'cat', 'item', 'user_merchant', 'user_brand', 'user_cat', 'merchant_brand', 'merchant_cat']\n",
    "groups = [users, merchants, brands, categories, items, users_merchants, users_brands, users_categories, merchant_brands, merchant_categories]\n",
    "\n",
    "for i in range(len(str_list)):\n",
    "    if i >= 5:\n",
    "        keys = str_list[i].split('_')\n",
    "        merge_keys = [f\"{keys[0]}_id\", f\"{keys[1]}_id\"]\n",
    "    else:\n",
    "        merge_keys = str_list[i] + '_id'\n",
    "    # Count total actions type for given user\n",
    "    to_merge = groups[i]['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "        0: 'clicks_' + str_list[i], \n",
    "        1: 'carts_' + str_list[i], \n",
    "        2: 'purchases_' + str_list[i], \n",
    "        3: 'favourites_'+ str_list[i]\n",
    "    })\n",
    "    df = df.merge(to_merge, on=merge_keys, how='left')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Action Count Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list = ['user', 'merchant', 'brand', 'cat', 'item', 'user_merchant', 'user_brand', 'user_cat', 'merchant_brand', 'merchant_cat']\n",
    "\n",
    "for profile in str_list:\n",
    "    # Calculate the total actions for the profile\n",
    "    df[f'total_actions_{profile}'] = (\n",
    "        df[f'clicks_{profile}'] +\n",
    "        df[f'carts_{profile}'] +\n",
    "        df[f'purchases_{profile}'] +\n",
    "        df[f'favourites_{profile}']\n",
    "    )\n",
    "    \n",
    "    # Calculate action ratios~\n",
    "    df[f'clicks_ratio_{profile}'] = df[f'clicks_{profile}'] / (df[f'total_actions_{profile}'] + 1e-9)\n",
    "    df[f'carts_ratio_{profile}'] = df[f'carts_{profile}'] / (df[f'total_actions_{profile}'] + 1e-9)\n",
    "    df[f'purchases_ratio_{profile}'] = df[f'purchases_{profile}'] / (df[f'total_actions_{profile}'] + 1e-9)\n",
    "    df[f'favourites_ratio_{profile}'] = df[f'favourites_{profile}'] / (df[f'total_actions_{profile}'] + 1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Day Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list = ['user', 'merchant', 'brand', 'cat', 'item', 'user_merchant', 'user_brand', 'user_cat', 'merchant_brand', 'merchant_cat']\n",
    "groups = [users, merchants, brands, categories, items, users_merchants, users_brands, users_categories, merchant_brands, merchant_categories]\n",
    "\n",
    "for i in range(len(str_list)):\n",
    "    if i >= 5: \n",
    "        keys = str_list[i].split('_')\n",
    "        merge_keys = [f\"{keys[0]}_id\", f\"{keys[1]}_id\", 'time_stamp']\n",
    "        group_by_keys = [f\"{keys[0]}_id\", f\"{keys[1]}_id\", 'time_stamp', 'action_type']\n",
    "    else: \n",
    "        merge_keys = [f'{str_list[i]}_id', 'time_stamp']\n",
    "        group_by_keys = [f'{str_list[i]}_id', 'time_stamp', 'action_type']\n",
    "    \n",
    "    # Group by entity (or pair of entities), time_stamp, and action_type\n",
    "    to_merge = (\n",
    "        user_logs.groupby(group_by_keys).size().unstack(level=-1, fill_value=0).reset_index().rename(columns={\n",
    "            0: f'clicks_{str_list[i]}_per_day', \n",
    "            1: f'carts_{str_list[i]}_per_day', \n",
    "            2: f'purchases_{str_list[i]}_per_day', \n",
    "            3: f'favourites_{str_list[i]}_per_day'\n",
    "        })\n",
    "    )\n",
    "\n",
    "    df = df.merge(to_merge, on=merge_keys, how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Action Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list = ['user', 'merchant', 'brand', 'cat', 'item', 'user_merchant']\n",
    "groups = [users, merchants, brands, categories, items, users_merchants]\n",
    "\n",
    "for i in range(len(str_list)):\n",
    "    if i >= 5: \n",
    "        keys = str_list[i].split('_')  # Split for two-entity relationships\n",
    "        merge_keys = [f\"{keys[0]}_id\", f\"{keys[1]}_id\", 'time_period']\n",
    "        group_by_keys = [f\"{keys[0]}_id\", f\"{keys[1]}_id\", 'time_period', 'action_type']\n",
    "    else: \n",
    "        merge_keys = [f'{str_list[i]}_id', 'time_period']\n",
    "        group_by_keys = [f'{str_list[i]}_id', 'time_period', 'action_type']\n",
    "    \n",
    "    # Group by entity (or pair of entities), time_period, and action_type\n",
    "    to_merge = (\n",
    "        user_logs.groupby(group_by_keys)\n",
    "        .size()\n",
    "        .unstack(level=-1, fill_value=0)\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            0: f'clicks_{str_list[i]}_monthly', \n",
    "            1: f'carts_{str_list[i]}_monthly', \n",
    "            2: f'purchases_{str_list[i]}_monthly', \n",
    "            3: f'favourites_{str_list[i]}_monthly'\n",
    "        })\n",
    "    )\n",
    "\n",
    "    df = df.merge(to_merge, on=merge_keys, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Action Count Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list = ['user', 'merchant', 'brand', 'cat', 'item', 'user_merchant']\n",
    "\n",
    "for profile in str_list:\n",
    "    df[f'total_actions_{profile}_monthly'] = (\n",
    "        df[f'clicks_{profile}_monthly'] +\n",
    "        df[f'carts_{profile}_monthly'] +\n",
    "        df[f'purchases_{profile}_monthly'] +\n",
    "        df[f'favourites_{profile}_monthly']\n",
    "    )\n",
    "    \n",
    "    df[f'clicks_ratio_{profile}_monthly'] = df[f'clicks_{profile}_monthly'] / (df[f'total_actions_{profile}_monthly'] + 1e-9)\n",
    "    df[f'carts_ratio_{profile}_monthly'] = df[f'carts_{profile}_monthly'] / (df[f'total_actions_{profile}_monthly'] + 1e-9)\n",
    "    df[f'purchases_ratio_{profile}_monthly'] = df[f'purchases_{profile}_monthly'] / (df[f'total_actions_{profile}_monthly'] + 1e-9)\n",
    "    df[f'favourites_ratio_{profile}_monthly'] = df[f'favourites_{profile}_monthly'] / (df[f'total_actions_{profile}_monthly'] + 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = [\n",
    "    {'name': 'user', 'keys': ['user_id', 'time_period']},\n",
    "    {'name': 'merchant', 'keys': ['merchant_id', 'time_period']},\n",
    "    {'name': 'user_merchant', 'keys': ['user_id', 'merchant_id', 'time_period']}\n",
    "]\n",
    "\n",
    "diversity_entities = ['item_id', 'brand_id', 'cat_id']\n",
    "\n",
    "for profile in profiles:\n",
    "    for entity in diversity_entities:\n",
    "        diversity_features = (\n",
    "            user_logs.groupby(profile['keys'] + ['action_type'])[entity]\n",
    "            .nunique()\n",
    "            .unstack(level=-1, fill_value=0)\n",
    "            .reset_index()\n",
    "            .rename(columns={\n",
    "                0: f'unique_{entity}_clicks_{profile[\"name\"]}_monthly',\n",
    "                1: f'unique_{entity}_carts_{profile[\"name\"]}_monthly',\n",
    "                2: f'unique_{entity}_purchases_{profile[\"name\"]}_monthly',\n",
    "                3: f'unique_{entity}_favourites_{profile[\"name\"]}_monthly'\n",
    "            })\n",
    "        )\n",
    "\n",
    "        df = df.merge(diversity_features, on=profile['keys'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penetration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "purchase_penetration:\n",
    "Number of unique users who purchased the given entity within a time period.\n",
    "\n",
    "interaction_penetration:\n",
    "Proportion of unique users interacting with the entity relative to the total unique users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ['item_id', 'merchant_id', 'brand_id', 'cat_id']\n",
    "\n",
    "for entity in entities:\n",
    "    # PURCHASE-BASED PENETRATION\n",
    "    purchase_penetration = (\n",
    "        user_logs[user_logs['action_type'] == 2]  # Filter for purchases\n",
    "        .groupby([entity, 'time_period'])['user_id']\n",
    "        .nunique()\n",
    "        .reset_index()\n",
    "        .rename(columns={'user_id': f'{entity}_purchase_penetration'})\n",
    "    ).fillna(0)\n",
    "\n",
    "    # INTERACTION-BASED PENETRATION\n",
    "    total_users = user_logs['user_id'].nunique()  # Total unique users\n",
    "    interaction_penetration = (\n",
    "        user_logs.groupby([entity, 'time_period'])['user_id']\n",
    "        .nunique()  \n",
    "        .reset_index()\n",
    "        .rename(columns={'user_id': f'{entity}_interaction_penetration'})\n",
    "    )\n",
    "    interaction_penetration[f'{entity}_interaction_penetration'] /= total_users  # Normalize\n",
    "    \n",
    "    df = df.merge(purchase_penetration, on=[entity, 'time_period'], how='left')\n",
    "    df = df.merge(interaction_penetration, on=[entity, 'time_period'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = ['mean', 'std', 'max', 'median']\n",
    "entities = ['merchant_id', 'brand_id', 'cat_id', 'user_merchant']\n",
    "\n",
    "action_types = {0: 'clicks', 3: 'favourites'}\n",
    "\n",
    "purchase_log = user_logs[user_logs['action_type'] == 2]\n",
    "\n",
    "for entity in entities:\n",
    "    if entity == 'user_merchant':\n",
    "        group_keys = ['user_id', 'merchant_id']\n",
    "        aggregate_keys = ['merchant_id']\n",
    "    else:\n",
    "        group_keys = ['user_id', entity]\n",
    "        aggregate_keys = [entity]\n",
    "\n",
    "    # USER-PURCHASE-DAY AGGREGATION\n",
    "    user_purchase_day = (\n",
    "        purchase_log.groupby(group_keys)['time_stamp'].nunique().reset_index().rename(columns={\n",
    "            'time_stamp': f'user_purchase_days_{entity}'\n",
    "            })\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # USER-PURCHASE-ITEM AGGREGATION\n",
    "    user_purchase_item = (\n",
    "        purchase_log.groupby(group_keys)['item_id'].nunique().reset_index().rename(columns={\n",
    "            'item_id': f'user_purchase_items_{entity}'\n",
    "            })\n",
    "    ).fillna(0)\n",
    "\n",
    "    purchase_day_aggregations = (\n",
    "        user_purchase_day.groupby(aggregate_keys)[f'user_purchase_days_{entity}']\n",
    "        .agg(aggregations)\n",
    "        .reset_index()\n",
    "        .rename(columns={metric: f'user_purchase_days_{entity}_{metric}' for metric in aggregations})\n",
    "    )\n",
    "\n",
    "    purchase_item_aggregations = (\n",
    "        user_purchase_item.groupby(aggregate_keys)[f'user_purchase_items_{entity}']\n",
    "        .agg(aggregations)\n",
    "        .reset_index()\n",
    "        .rename(columns={metric: f'user_purchase_items_{entity}_{metric}' for metric in aggregations})\n",
    "    )\n",
    "\n",
    "    df = df.merge(purchase_day_aggregations, on=aggregate_keys, how='left')\n",
    "    df = df.merge(purchase_item_aggregations, on=aggregate_keys, how='left')\n",
    "\n",
    "    # Calculate features for clicks and favourites for merchants only\n",
    "    if entity == 'merchant_id':\n",
    "        for action, action_name in action_types.items():\n",
    "            user_action_day = (\n",
    "                user_logs[user_logs['action_type'] == action]\n",
    "                .groupby(group_keys)['time_stamp'].nunique()\n",
    "                .reset_index()\n",
    "                .rename(columns={'time_stamp': f'user_{action_name}_days_{entity}'})\n",
    "            ).fillna(0)\n",
    "\n",
    "            user_action_item = (\n",
    "                user_logs[user_logs['action_type'] == action]\n",
    "                .groupby(group_keys)['item_id'].nunique()\n",
    "                .reset_index()\n",
    "                .rename(columns={'item_id': f'user_{action_name}_items_{entity}'})\n",
    "            ).fillna(0)\n",
    "\n",
    "            action_day_aggregations = (\n",
    "                user_action_day.groupby(aggregate_keys)[f'user_{action_name}_days_{entity}']\n",
    "                .agg(aggregations)\n",
    "                .reset_index()\n",
    "                .rename(columns={metric: f'user_{action_name}_days_{entity}_{metric}' for metric in aggregations})\n",
    "            )\n",
    "\n",
    "            action_item_aggregations = (\n",
    "                user_action_item.groupby(aggregate_keys)[f'user_{action_name}_items_{entity}']\n",
    "                .agg(aggregations)\n",
    "                .reset_index()\n",
    "                .rename(columns={metric: f'user_{action_name}_items_{entity}_{metric}' for metric in aggregations})\n",
    "            )\n",
    "\n",
    "            df = df.merge(action_day_aggregations, on=aggregate_keys, how='left')\n",
    "            df = df.merge(action_item_aggregations, on=aggregate_keys, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merchant Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['mean', 'std', 'max', 'median']\n",
    "\n",
    "merchant_aggregation_features = {}\n",
    "\n",
    "merchant_purchase_day = (\n",
    "    user_logs[user_logs['action_type'] == 2]  \n",
    "    .groupby(['user_id', 'merchant_id'])['time_stamp']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'time_stamp': 'merchant_purchase_days'})\n",
    ")\n",
    "\n",
    "merchant_purchase_day_agg = (\n",
    "    merchant_purchase_day.groupby('user_id')['merchant_purchase_days']\n",
    "    .agg(metrics)\n",
    "    .reset_index()\n",
    "    .rename(columns={metric: f'merchant_purchase_days_{metric}' for metric in metrics})\n",
    ")\n",
    "merchant_aggregation_features['purchase_day'] = merchant_purchase_day_agg\n",
    "\n",
    "merchant_purchase_item = (\n",
    "    user_logs[user_logs['action_type'] == 2] \n",
    "    .groupby(['user_id', 'merchant_id'])['item_id']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'item_id': 'merchant_purchase_items'})\n",
    ")\n",
    "\n",
    "merchant_purchase_item_agg = (\n",
    "    merchant_purchase_item.groupby('user_id')['merchant_purchase_items']\n",
    "    .agg(metrics)\n",
    "    .reset_index()\n",
    "    .rename(columns={metric: f'merchant_purchase_items_{metric}' for metric in metrics})\n",
    ")\n",
    "merchant_aggregation_features['purchase_item'] = merchant_purchase_item_agg\n",
    "\n",
    "action_types = {0: 'clicks', 1: 'carts', 2: 'purchases', 3: 'favourites'}\n",
    "\n",
    "for action, action_name in action_types.items():\n",
    "    merchant_action_day = (\n",
    "        user_logs[user_logs['action_type'] == action]\n",
    "        .groupby(['user_id', 'merchant_id'])['time_stamp']\n",
    "        .nunique()\n",
    "        .reset_index()\n",
    "        .rename(columns={'time_stamp': f'merchant_{action_name}_days'})\n",
    "    )\n",
    "\n",
    "    merchant_action_day_agg = (\n",
    "        merchant_action_day.groupby('user_id')[f'merchant_{action_name}_days']\n",
    "        .agg(metrics)\n",
    "        .reset_index()\n",
    "        .rename(columns={metric: f'merchant_{action_name}_days_{metric}' for metric in metrics})\n",
    "    )\n",
    "    merchant_aggregation_features[f'{action_name}_day'] = merchant_action_day_agg\n",
    "\n",
    "for feature_name, feature_df in merchant_aggregation_features.items():\n",
    "    df = df.merge(feature_df, on='user_id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double 11 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOUBLE_11= 184 # min date is 511\n",
    "double_11_log = (user_logs[user_logs['time_stamp'] ==DOUBLE_11]).reset_index(drop=True)\n",
    "\n",
    "double_11_users= double_11_log.groupby('user_id')\n",
    "double_11_merchant = double_11_log.groupby('merchant_id')\n",
    "ouble_11_categories = double_11_log.groupby('cat_id')\n",
    "double_11_brand = double_11_log.groupby('brand_id')\n",
    "double_11_item = double_11_log.groupby('item_id')\n",
    "double_11_user_merchant = double_11_log.groupby(['user_id','merchant_id'])\n",
    "# counts of clicks, purchase, addto favourite\n",
    "\n",
    "# Count each action type for each user\n",
    "# count total number of unique values from each feature for a given user \n",
    "# count total number of unique values from each feature for a given user \n",
    "to_merge = double_11_users.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'double_11_items_user', \n",
    "    'cat_id': 'double_11_categories_user',\n",
    "    'merchant_id': 'double_11_merchants_user',\n",
    "    'brand_id': 'double_11_brands_user',\n",
    "    'time_stamp': 'double_11_dates_user',\n",
    "    'time_period': 'double_11_periods_user',\n",
    "    'action_type': 'double_11_action_types_user'\n",
    "    })\n",
    "\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# count total number of unique values from each feature for a given merchant \n",
    "to_merge = double_11_merchant.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'double_11_items_merchant', \n",
    "    'cat_id': 'double_11_categories_merchant',\n",
    "    'user_id': 'double_11_users_merchant',\n",
    "    'brand_id': 'double_11_brands_merchant',\n",
    "    'time_stamp': 'double_11_dates_merchant',\n",
    "    'time_period': 'double_11_periods_merchant',\n",
    "    'action_type': 'double_11_action_types_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# count total number of unique values from each feature for a given user and merchant\n",
    "to_merge = double_11_user_merchant.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'double_11_items_user_merchant', \n",
    "    'cat_id': 'double_11_categories_user_merchant',\n",
    "    'brand_id': 'double_11_brands_user_merchant',\n",
    "    'time_stamp': 'double_11_dates_user_merchant',\n",
    "    'time_period': 'double_11_periods_user_merchant',\n",
    "    'action_type': 'double_11_action_types_user_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# count total actions by type for a given user\n",
    "to_merge = double_11_users['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'double_11_clicks_user',\n",
    "    1: 'double_11_carts_user',\n",
    "    2: 'double_11_purchases_user',\n",
    "    3: 'double_11_favourites_user'\n",
    "    })\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# count total actions by type for a given merchant\n",
    "to_merge = double_11_merchant['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'double_11_clicks_merchant', \n",
    "    1: 'double_11_carts_merchant',\n",
    "    2: 'double_11_purchases_merchant',\n",
    "    3: 'double_11_favourites_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# count total actions by type for a given pair (user, merchant)\n",
    "to_merge = double_11_user_merchant['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'double_11_clicks_user_merchant',\n",
    "    1: 'double_11_carts_user_merchant',\n",
    "    2: 'double_11_purchases_user_merchant',\n",
    "    3: 'double_11_favourites_user_merchant'\n",
    "    })\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['user', 'merchant', 'user_merchant']\n",
    "action_types = ['clicks', 'carts', 'purchases', 'favourites']\n",
    "\n",
    "EPSILON = 1e-8\n",
    "\n",
    "# Compute ratios for features in user, merchant, and user-merchant categories\n",
    "for group in groups:\n",
    "    for feature in ['items', 'categories', 'brands', 'dates', 'periods', 'action_types']:\n",
    "        # Feature ratio for each group relative to itself\n",
    "        df[f'double_11_{feature}_{group}_ratio'] = df[f'double_11_{feature}_{group}'] / (df[f'double_11_{feature}_{group}'] + EPSILON)\n",
    "        df[f'double_11_{feature}_{group}_ratio'] = df[f'double_11_{feature}_{group}'] / (df[f'{feature}_{group}'] + EPSILON)\n",
    "\n",
    "# Compute ratios for actions from the user perspective\n",
    "for action in action_types:\n",
    "    # Ratio within double_11 actions\n",
    "    df[f'double_11_{action}_user_ratio'] = df[f'double_11_{action}_user'] / (\n",
    "        df['double_11_clicks_user'] + df['double_11_carts_user'] + df['double_11_purchases_user'] + df['double_11_favourites_user'] + EPSILON\n",
    "    )\n",
    "    df[f'double_11_{action}_user_ratio'] = df[f'double_11_{action}_user'] / (df[f'{action}_user'] + EPSILON)\n",
    "\n",
    "# Compute ratios for actions from the merchant perspective\n",
    "for action in action_types:\n",
    "    # Ratio within double_11 actions\n",
    "    df[f'double_11_{action}_merchant_ratio'] = df[f'double_11_{action}_merchant'] / (\n",
    "        df['double_11_clicks_merchant'] + df['double_11_carts_merchant'] + df['double_11_purchases_merchant'] + df['double_11_favourites_merchant'] + EPSILON\n",
    "    )\n",
    "    df[f'double_11_{action}_merchant_ratio'] = df[f'double_11_{action}_merchant'] / (df[f'{action}_merchant'] + EPSILON)\n",
    "\n",
    "# Compute ratios for actions from the user-merchant perspective\n",
    "for action in action_types:\n",
    "    # Ratio within double_11 actions\n",
    "    df[f'double_11_{action}_user_merchant_ratio'] = df[f'double_11_{action}_user_merchant'] / (\n",
    "        df['double_11_clicks_user_merchant'] + df['double_11_carts_user_merchant'] + df['double_11_purchases_user_merchant'] + df['double_11_favourites_user_merchant'] + EPSILON\n",
    "    )\n",
    "    # Ratio of actions compared to total user-merchant actions\n",
    "    df[f'double_11_{action}_user_merchant_ratio'] = df[f'double_11_{action}_user_merchant'] / (df[f'{action}_user_merchant'] + EPSILON)\n",
    "\n",
    "# Ratio of actions in each merchant (user perspective)\n",
    "for action in action_types:\n",
    "    df[f'double_11_{action}_in_merchant_ratio_perspective'] = df[f'double_11_{action}_user_merchant'] / (df[f'double_11_{action}_user'] + EPSILON)\n",
    "\n",
    "# Ratio of actions in each merchant (merchant perspective)\n",
    "for action in action_types:\n",
    "    df[f'double_11_{action}_by_user_ratio_perspective'] = df[f'double_11_{action}_user_merchant'] / (df[f'double_11_{action}_merchant'] + EPSILON)\n",
    "\n",
    "# Ratio of each action type for a given user\n",
    "for action in action_types:\n",
    "    df[f'double_11_{action}_user_ratio'] = df[f'double_11_{action}_user'] / (\n",
    "        df['double_11_clicks_user'] + df['double_11_carts_user'] + df['double_11_purchases_user'] + df['double_11_favourites_user'] + EPSILON\n",
    "    )\n",
    "\n",
    "# Ratio of each action type for a given merchant\n",
    "for action in action_types:\n",
    "    df[f'double_11_{action}_merchant_ratio'] = df[f'double_11_{action}_merchant'] / (\n",
    "        df['double_11_clicks_merchant'] + df['double_11_carts_merchant'] + df['double_11_purchases_merchant'] + df['double_11_favourites_merchant'] + EPSILON\n",
    "    )\n",
    "\n",
    "# Ratio of each action type for a given pair (user, merchant)\n",
    "for action in action_types:\n",
    "    df[f'double_11_{action}_user_merchant_ratio'] = df[f'double_11_{action}_user_merchant'] / (\n",
    "        df['double_11_clicks_user_merchant'] + df['double_11_carts_user_merchant'] + df['double_11_purchases_user_merchant'] + df['double_11_favourites_user_merchant'] + EPSILON\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latest one week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_one_week_log = user_logs[\n",
    "    (user_logs['time_stamp'] >= DOUBLE_11 - 7) & \n",
    "    (user_logs['time_stamp'] < DOUBLE_11 )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "\n",
    "latest_one_week_users = latest_one_week_log.groupby('user_id')\n",
    "latest_one_week_merchant = latest_one_week_log.groupby('merchant_id')\n",
    "latest_one_week_categories = latest_one_week_log.groupby('cat_id')\n",
    "latest_one_week_brand = latest_one_week_log.groupby('brand_id')\n",
    "latest_one_week_item = latest_one_week_log.groupby('item_id')\n",
    "latest_one_week_user_merchant = latest_one_week_log.groupby(['user_id', 'merchant_id'])\n",
    "\n",
    "# Count each action type for each user\n",
    "# Count total number of unique values from each feature for a given user\n",
    "to_merge = latest_one_week_users.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'latest_one_week_items_user', \n",
    "    'cat_id': 'latest_one_week_categories_user',\n",
    "    'merchant_id': 'latest_one_week_merchants_user',\n",
    "    'brand_id': 'latest_one_week_brands_user',\n",
    "    'time_stamp': 'latest_one_week_dates_user',\n",
    "    'time_period': 'latest_one_week_periods_user',\n",
    "    'action_type': 'latest_one_week_action_types_user'\n",
    "})\n",
    "\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# Count total number of unique values from each feature for a given merchant\n",
    "to_merge = latest_one_week_merchant.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'latest_one_week_items_merchant', \n",
    "    'cat_id': 'latest_one_week_categories_merchant',\n",
    "    'user_id': 'latest_one_week_users_merchant',\n",
    "    'brand_id': 'latest_one_week_brands_merchant',\n",
    "    'time_stamp': 'latest_one_week_dates_merchant',\n",
    "    'time_period': 'latest_one_week_periods_merchant',\n",
    "    'action_type': 'latest_one_week_action_types_merchant'\n",
    "})\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# Count total number of unique values from each feature for a given user and merchant\n",
    "to_merge = latest_one_week_user_merchant.nunique().reset_index().rename(columns={\n",
    "    'item_id': 'latest_one_week_items_user_merchant', \n",
    "    'cat_id': 'latest_one_week_categories_user_merchant',\n",
    "    'brand_id': 'latest_one_week_brands_user_merchant',\n",
    "    'time_stamp': 'latest_one_week_dates_user_merchant',\n",
    "    'time_period': 'latest_one_week_periods_user_merchant',\n",
    "    'action_type': 'latest_one_week_action_types_user_merchant'\n",
    "})\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# Count total actions by type for a given user\n",
    "to_merge = latest_one_week_users['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'latest_one_week_clicks_user',\n",
    "    1: 'latest_one_week_carts_user',\n",
    "    2: 'latest_one_week_purchases_user',\n",
    "    3: 'latest_one_week_favourites_user'\n",
    "})\n",
    "df = df.merge(to_merge, on='user_id', how='left')\n",
    "\n",
    "# Count total actions by type for a given merchant\n",
    "to_merge = latest_one_week_merchant['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'latest_one_week_clicks_merchant', \n",
    "    1: 'latest_one_week_carts_merchant',\n",
    "    2: 'latest_one_week_purchases_merchant',\n",
    "    3: 'latest_one_week_favourites_merchant'\n",
    "})\n",
    "df = df.merge(to_merge, on='merchant_id', how='left')\n",
    "\n",
    "# Count total actions by type for a given pair (user, merchant)\n",
    "to_merge = latest_one_week_user_merchant['action_type'].value_counts().unstack(fill_value=0).rename(columns={\n",
    "    0: 'latest_one_week_clicks_user_merchant',\n",
    "    1: 'latest_one_week_carts_user_merchant',\n",
    "    2: 'latest_one_week_purchases_user_merchant',\n",
    "    3: 'latest_one_week_favourites_user_merchant'\n",
    "})\n",
    "df = df.merge(to_merge, on=['user_id', 'merchant_id'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio for one week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['user', 'merchant', 'user_merchant']\n",
    "action_types = ['clicks', 'carts', 'purchases', 'favourites']\n",
    "\n",
    "EPSILON = 1e-8\n",
    "\n",
    "# Compute ratios for features in user, merchant, and user-merchant categories\n",
    "for group in groups:\n",
    "    for feature in ['items', 'categories', 'brands', 'dates', 'periods', 'action_types']:\n",
    "        # Feature ratio for each group relative to itself\n",
    "        df[f'latest_one_week_{feature}_{group}_ratio'] = df[f'latest_one_week_{feature}_{group}'] / (df[f'latest_one_week_{feature}_{group}'] + EPSILON)\n",
    "        df[f'latest_one_week_{feature}_{group}_ratio'] = df[f'latest_one_week_{feature}_{group}'] / (df[f'{feature}_{group}'] + EPSILON)\n",
    "\n",
    "# Compute ratios for actions from the user perspective\n",
    "for action in action_types:\n",
    "    # Ratio within latest_one_week actions\n",
    "    df[f'latest_one_week_{action}_user_ratio'] = df[f'latest_one_week_{action}_user'] / (\n",
    "        df['latest_one_week_clicks_user'] + df['latest_one_week_carts_user'] + df['latest_one_week_purchases_user'] + df['latest_one_week_favourites_user'] + EPSILON\n",
    "    )\n",
    "    df[f'latest_one_week_{action}_user_ratio'] = df[f'latest_one_week_{action}_user'] / (df[f'{action}_user'] + EPSILON)\n",
    "\n",
    "# Compute ratios for actions from the merchant perspective\n",
    "for action in action_types:\n",
    "    # Ratio within latest_one_week actions\n",
    "    df[f'latest_one_week_{action}_merchant_ratio'] = df[f'latest_one_week_{action}_merchant'] / (\n",
    "        df['latest_one_week_clicks_merchant'] + df['latest_one_week_carts_merchant'] + df['latest_one_week_purchases_merchant'] + df['latest_one_week_favourites_merchant'] + EPSILON\n",
    "    )\n",
    "    df[f'latest_one_week_{action}_merchant_ratio'] = df[f'latest_one_week_{action}_merchant'] / (df[f'{action}_merchant'] + EPSILON)\n",
    "\n",
    "# Compute ratios for actions from the user-merchant perspective\n",
    "for action in action_types:\n",
    "    # Ratio within latest_one_week actions\n",
    "    df[f'latest_one_week_{action}_user_merchant_ratio'] = df[f'latest_one_week_{action}_user_merchant'] / (\n",
    "        df['latest_one_week_clicks_user_merchant'] + df['latest_one_week_carts_user_merchant'] + df['latest_one_week_purchases_user_merchant'] + df['latest_one_week_favourites_user_merchant'] + EPSILON\n",
    "    )\n",
    "    # Ratio of actions compared to total user-merchant actions\n",
    "    df[f'latest_one_week_{action}_user_merchant_ratio'] = df[f'latest_one_week_{action}_user_merchant'] / (df[f'{action}_user_merchant'] + EPSILON)\n",
    "\n",
    "# Ratio of actions in each merchant (user perspective)\n",
    "for action in action_types:\n",
    "    df[f'latest_one_week_{action}_in_merchant_ratio_perspective'] = df[f'latest_one_week_{action}_user_merchant'] / (df[f'latest_one_week_{action}_user'] + EPSILON)\n",
    "\n",
    "# Ratio of actions in each merchant (merchant perspective)\n",
    "for action in action_types:\n",
    "    df[f'latest_one_week_{action}_by_user_ratio_perspective'] = df[f'latest_one_week_{action}_user_merchant'] / (df[f'latest_one_week_{action}_merchant'] + EPSILON)\n",
    "\n",
    "# Ratio of each action type for a given user\n",
    "for action in action_types:\n",
    "    df[f'latest_one_week_{action}_user_ratio'] = df[f'latest_one_week_{action}_user'] / (\n",
    "        df['latest_one_week_clicks_user'] + df['latest_one_week_carts_user'] + df['latest_one_week_purchases_user'] + df['latest_one_week_favourites_user'] + EPSILON\n",
    "    )\n",
    "\n",
    "# Ratio of each action type for a given merchant\n",
    "for action in action_types:\n",
    "    df[f'latest_one_week_{action}_merchant_ratio'] = df[f'latest_one_week_{action}_merchant'] / (\n",
    "        df['latest_one_week_clicks_merchant'] + df['latest_one_week_carts_merchant'] + df['latest_one_week_purchases_merchant'] + df['latest_one_week_favourites_merchant'] + EPSILON\n",
    "    )\n",
    "\n",
    "# Ratio of each action type for a given pair (user, merchant)\n",
    "for action in action_types:\n",
    "    df[f'latest_one_week_{action}_user_merchant_ratio'] = df[f'latest_one_week_{action}_user_merchant'] / (\n",
    "        df['latest_one_week_clicks_user_merchant'] + df['latest_one_week_carts_user_merchant'] + df['latest_one_week_purchases_user_merchant'] + df['latest_one_week_favourites_user_merchant'] + EPSILON\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0 for all columns except 'label'\n",
    "df.loc[:, df.columns != 'label'] = df.loc[:, df.columns != 'label'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = df.drop(['type', 'label'], axis=1)\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(pca_df)\n",
    "df = df.join(pd.DataFrame(pca.transform(pca_df), index=pca_df.index).add_prefix('pca_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing Touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['type'] == 'train'].drop(['type'], axis=1)\n",
    "df_test = df[df['type'] == 'test'].drop(['type', 'label'], axis=1)\n",
    "X, y = df_train.drop(columns='label'), df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"X_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_csv(\"y_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470168, 527)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0], X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
